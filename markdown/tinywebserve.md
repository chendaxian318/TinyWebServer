# TinyWebserver

## 1:半同步半反应堆线程池

### 1.1服务器编程基本框架

**由I/O单元，逻辑单元，网络存储单元组成**

**I/O单元**：处理客户端连接，读写网络数据，

**逻辑单元**：处理业务逻辑的线程

**网络存储单元**：本地数据库与文件数据等

### 1.2五种I/O模型

**阻塞IO**:在应用调用recvfrom读取数据时，系统调用在数据包到达且被复制到应用缓冲区中或发送错误时才被返回。

在此期间会进行等待，进程在调用到返回时的这段时间内都是被阻塞的，称为阻塞IO。

例如：当client调用recvfrom接受数据时，缓冲区为空，client会一直等待，直到server发送的数据且发送的数据被复制到应用缓冲区时才能接受数据，完成recvfrom的调用。

**流程**：

1、应用进程向内核发起recfrom读取数据

2、准备数据报（应用进程阻塞）

3、将数据从内核复制到应用空间

4、复制完成后，返回成功提示

![image-20240430110714789](C:\Users\陈大仙\AppData\Roaming\Typora\typora-user-images\image-20240430110714789.png)

**非阻塞IO**:当应用发起读取数据申请时，内核数据有没有准备好都会立刻完成调用返回给应用程序，如果缓冲区中没有数据，会直接返回一个EWOULDBOLCK错误。所以如果应用要读取数据就需要不断的调用recvfrom请求，直到读取到它想要的数据为止。

![image-20240430110738155](C:\Users\陈大仙\AppData\Roaming\Typora\typora-user-images\image-20240430110738155.png)

**流程**:

1、应用进程向内核发起recvfrom读取数据

2、没有数据准备好，即刻返回EWOULDBLOCK错误码

3、应用进程向内核发起recvfrom读取数据

4、已有数据包准备好就进行下一步骤，否则还是返回错误码

5、将数据从内核拷贝到用户空间

6、完成后，返回成功提示

### I/O多路复用之select,poll,epoll

I/O多路复用是一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪，能够通知程序进行相应的操作，但I/O多路复用本质上也还是同步IO,因为他们都需要在读写时间就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间


		<video src="C:\Users\陈大仙\Desktop\学习记录\markdown\tinywebserve\select.mp4"></video>


[1] 每次调用select，都需要把被监控的fds集合从用户态空间拷贝到内核态空间，高并发场景下这样的拷贝会使得消耗的资源是很大的。
[2] 能监听端口的数量有限，单个进程所能打开的最大连接数由FD_SETSIZE宏定义，监听上限就等于fds_bits位数组中所有元素的二进制位总数，其大小是32个整数的大小（在32位的机器上，大小就是3232，同理64位机器上为3264），当然我们可以对宏FD_SETSIZE进行修改，然后重新编译内核，但是性能可能会受到影响，一般该数和系统内存关系很大，具体数目可以`cat /proc/sys/fs/file-max`察看。32位机默认1024个，64位默认2048.

[3] 被监控的fds集合中，只要有一个有数据可读，整个socket集合就会被遍历一次调用sk的poll函数收集可读事件：由于当初的需求是朴素，仅仅关心是否有数据可读这样一个事件，当事件通知来的时候，由于数据的到来是异步的，我们不知道事件来的时候，有多少个被监控的socket有数据可读了，于是，只能挨个遍历每个socket来收集可读事件了。

**poll**

poll的实现和select非常相似，只是描述fd集合的方式不同。针对select遗留的三个问题中（问题(2)是fd限制问题，问题(1)和(3)则是性能问题），poll只是使用pollfd结构而不是select的fd_set结构，这就解决了select的问题(2)fds集合大小1024限制问题。但poll和select同样存在一个性能缺点就是包含大量文件描述符的数组被整体复制于用户态和内核的地址空间之间，而不论这些文件描述符是否就绪，它的开销随着文件描述符数量的增加而线性增大。

**epoll**



### 信号驱动IO

<video src="C:\Users\陈大仙\Desktop\学习记录\markdown\tinywebserve\epoll.mp4"></video>

在调用sigaction时简历一个SIGIO信号联系，当内核数据准备好之后通过SIGIO信号通知线程数据准备好后的可读状态，当线程收到可读状态的信号后，此时再向内核发起读取数据的请求。信号驱动IO模型下应用线程在发出信号监控后即可返回，不会阻塞。一个应用线程可以同时监控多个fd

![image-20240430111551445](C:\Users\陈大仙\AppData\Roaming\Typora\typora-user-images\image-20240430111551445.png)

例子：开启套接口信号驱动IO功能，并通过系统调用sigaction执行一个信号处理函数，此时请求即刻返回，当数据准备就绪时，就生成对应进程的SIGIO信号，通过信号回调通知应用线程调用recvfrom来读取数据。与select相比，避免大量无效的数据状态轮询操作

![image-20240430113853127](C:\Users\陈大仙\AppData\Roaming\Typora\typora-user-images\image-20240430113853127.png)



### 异步IO

应用向内核发送一个read请求，告诉内核它要读取数据后即刻返回；内核收到请求后会建立一个信号联系，当数据准备就绪，内核会主动把数据从内核复制到用户空间，等所有操作都完成后，内核会发起一个通知告诉应用。

![image-20240430140701878](C:\Users\陈大仙\AppData\Roaming\Typora\typora-user-images\image-20240430140701878.png)

**例子**：应用告知内核启动某个操作，并让内核在整个操作完成后通知应用。与信号驱动IO模型的区别是信号驱动IO模型只是由内核通知我们可以开始IO操作，而异步IO模型是由内核通知我们操作什么时候完成

![image-20240430141154577](C:\Users\陈大仙\AppData\Roaming\Typora\typora-user-images\image-20240430141154577.png)

## 1.3事件处理模式

服务器程序通常要处理三类事件：I/O事件，信号，定时事件

**Reactor模式**:主线程（I/O处理单元）只负责监听文件描述符上是否有事件发生，有的话立刻通知工作线程（逻辑单元），除此之外，主线程不做任何其它实质性的工作，读写数据，接受新的连接，以及处理客户请求均在工作线程中完成

使用同步I/O模型实现的Reactor模式的工作流程是：

1、主线程往epoll内核事件表中注册socket上的读就绪事件

2、主线程调用epoll_wait等待socket上有数据可读

3、当socket上有数据可读时，epoll_wait通知主线程，主线程则将socket可读事件放入请求队列中

4、睡眠在请求队列上的某个工作线程被唤醒，从socket中读取数据，并处理客户请求，然后往epoll内核事件表中注册该socket上的写就绪事件

5、主线程调用epoll_wait等待socket可写

6、当socket可写时，epoll_wait通知主线程。主线程将sockey可写事件放入请求队列

7、睡眠在请求队列上的某个工作线程被唤醒，它往socket上写入服务器处理客户请求的结果

![image-20240430145202955](C:\Users\陈大仙\AppData\Roaming\Typora\typora-user-images\image-20240430145202955.png)

工作线程从请求队列中取出事件后，将根据事件类型来决定如何处理它；对于可读事件，执行读数据和处理请求的操作；对于可写事件执行写数据的操作。因此，Reactor模式中没必要区分所谓的“读工作线程”和“写工作线程”

**Proactor**：与Reactor模式不同，Proactor模式将所有的I/O操作都交给主线程来处理，工作线程仅仅只负责业务逻辑。

使用异步I/O模型(以aio_read和aio_write为例)实现的Proactor模式的工作流程是：

1、主线程调用aio_read函数向内核注册socket上的读完成事件，并告诉内核用户读缓冲区的位置，以及读操作完成时如何通知应用程序（这里以信号为例）

2、主线程继续处理其它逻辑

3、当socket上的数据被读入用户缓冲区后，内核将向应用程序发送一个信号，以通知应用程序数据已经可用

4、应用程序预先定义好的信号处理函数选择一个工作线程来处理客户请求。工作线程处理完客户请求后，调用aio_write函数向内核注册socket上的写完事件，并告诉内核用户写缓冲区的位置，以及写操作完成时如何通知应用程序（仍然以信号为例）

5、主线程继续处理其它逻辑

6、当用户缓冲区的数据被写入socket之后，内核将向应用程序发送一个信号，以通知应用程序数据已经发送完毕

7、应用程序预先定义好的信号处理函数选择一个工作线程来做善后处理，比如决定是否关闭socket

![image-20240430152008319](C:\Users\陈大仙\AppData\Roaming\Typora\typora-user-images\image-20240430152008319.png)

连接socket上的读写事件时通过aio_read/aio_write向内核注册的，因此内核将通过信号来向应用程序报告连接socket上的读写事件。所以，主线程中的epoll_write调用仅能用来监听socket上的连接请求事件，而不能用来检测socket上的读写事件。

**模拟Proactor模式**：主线程执行数据读写操作，读写完成后，主线程向工作线程通知这一“完成事件”。那么从工作线程的角度来看，它们直接获取到了数据读写的结果，接下来要做的只是对读写的结果进行逻辑处理。

使用同步I/O模型（仍以epoll_wait为例）模拟出了Proactor模式的工作流程如下：

1、主线程往epoll内核时间表中注册读就绪事件

2、主线程调用epoll_wait等待有数据可读

3、当socket上有数据可读，epoll_wait通知主线程。主线程从socket循环读取数据，直到没有更多数据可读，然后将读取到的数据封装成一个请求对象并插入请求队列中

4、睡眠在请求队列上的某个工作线程被唤醒，它获得请求对象并处理客户请求，然后往epoll内核事件表中注册socket上的写就绪事件。

5、当socket可写时，epoll_wait通知主线程，主线程往socket上写入服务器处理客户请求的结果

![image-20240430153852691](C:\Users\陈大仙\AppData\Roaming\Typora\typora-user-images\image-20240430153852691.png)

### 线程池

1、空间换时间，浪费服务器的硬件资源，换取运行效率

2、池是一组数据的集合，这组资源在服务器启动之初就被完全创建好并初始化，这成为静态资源

3、当服务器进入正式运行阶段，开始处理客户请求的时候，如果它需要相关的资源。可以直接从池中获取，无需动态分配

4、当服务器处理完一个客户连接后，可以把相关的资源放回池中，无需执行系统调用释放资源。

为何**pthread_create**需要放入静态成员函数，因为静态成员函数中没有this指针，不会与**pthread_create**的第四个参数产生冲突

**主线程**：Proactor事件处理模式，主线程为异步线程，监听添加socket,若socket中发生读写事件则将任务加入到任务队列中，再由工作线程去完成任务队列中的读写任务操作。

## 6、HTTP连接处理(下)

### 6.1 mmap

#### mmap内存映射原理：

mmap内存映射的实现过程：总的来说可以分为三阶段

##### 1）进程启动映射过程，并在虚拟地址空间中为映射创建虚拟映射区域

1、进程在用户空间调用库函数mmap，原型void *mmap(void *start,size_t length,int prot,int flags,int fd,off_t offset);

2、在当前进程的虚拟地址空间中，寻找一段空闲的满足要求的连续的虚拟地址
3、为此虚拟区分配一个vm_area_struct结构，接着对这个结构的各个域进行了初始化
4、将新建的虚拟区结构（vm_area_struct）插入进程的虚拟地址区域链表或树中

##### 2）调用内核空间的系统调用函数mmap(不同于用户空间函数),实现文件物理地址和进程虚拟地址的一一映射关系

5、为映射分配了新的虚拟地址区域后，通过待映射的文件指针，在文件描述符表中找到了对应的文件描述符，通过文件描述符，连接到内核“已打开文件集”中该文件的文件结构体（struct file），每个文件结构体维护着和这个已打开文件相关各项信息
6、通过该文件的文件结构体，链接到file_operations模块，调用内核函数mmap，其原型为：int mmap(struct file *filp,struct vm_area_struct vm_area_struct *vma);不同于用户空间库函数
7、内核mmap函数通过虚拟文件系统inode模块定位到文件磁盘物理地址
8、通过remap_pfn_range函数建立页表，即实现了文件地址和虚拟地址区域的映射关系。此时，此片虚拟地址并没有任何数据关联到主存中。

##### 3）进程发起对这片映射空间的访问，引发缺页异常，实现文件内容到物理内存（主存）的拷贝

注：前两个阶段仅在于创建虚拟区间并完成地址映射，但是并没有将任何文件数据的拷贝至主存。真正的文件读取是当进程发起读或写操作时。
9、进程的读或写操作访问虚拟地址空间这一段映射地址，通过查询页表，发现这一段地址并不在物理页面上。因为目前只建立了地址映射。真正的硬盘数据还没有拷贝到内存中，因此引发缺页异常
10、缺页异常进行一系列判断，确定无非法操作后，内核发起请求调页过程。
11、调页过程先在交换缓存空间（swap cache）中寻找需要访问的内存页，如果没有则调用nopage函数把所缺的页从磁盘装入到主存中。
12、之后进程即可对这片主存进行读或者写的操作。如果写操作改变了其内容。一定时间后系统会自动回写脏页面到对应磁盘地址，也即完成了写入到文件的过程
注：修改过的脏页面不会立即更新回文件中，而是有一段时间的延迟，可以调用msync()来强制同步，这样所写的内容就能立即更新回文件里了。

#### mmap优点总结

1、对文件的读取操作跨过了页缓存，减少了数据的拷贝次数，用内存读写取代了I/O读写，提高了文件读取效率
2、实现了用户空间和内核空间的高效交互方式。两空间的各自修改操作可以直接反映在映射的区域内，从而被对方空间及时捕捉。
3、提供进程间共享及相互通信的方式。不管是父子进程还是无亲缘关系的进程，都可以将自身用户空间映射到同一个文件或匿名映射到同一片区域。从而通过各自对映射区域的改动，达到进程间通信和进程间共享的目的。
同时，如果进程A和进程B都映射了区域C，当A第一次读取C时通过缺页从磁盘复制文件页到内存中；但当B再读C的相同页面时，虽然也会产生缺页异常，但是不再需要从磁盘中复制文件过来，而可直接使用已经保存在内存中的文件数据。
4、可用于实现高效的大规模数据传输。内存空间不足，是制约大数据操作的一个方面，解决方案往往是借助硬盘空间协助操作，补充内存空间的不足。但是会进一步造成大量I/O操作，极大影响效率。这个问题可以通过mmap映射很好的解决。换句话说，但凡是需要用磁盘空间代替内存的时候，mmap都可以发挥其功效。

### 流程图



![640](C:\Users\陈大仙\Desktop\学习记录\markdown\tinywebserve\640.webp)

## 7、定时器处理非活跃连接（上）

**非活跃**，是指客户端（这里是浏览器）与服务器端建立连接后，长时间不交换数据，一直占用服务器端的[文件描述符](https://so.csdn.net/so/search?q=文件描述符&spm=1001.2101.3001.7020)，导致连接资源的浪费。

**定时事件**，是指固定一段时间之后触发某段代码，由该段代码处理一个事件，如从内核事件表删除事件，并关闭文件描述符，释放连接资源。
**定时器**，是指利用[结构体](https://so.csdn.net/so/search?q=结构体&spm=1001.2101.3001.7020)或其他形式，将多种定时事件进行封装起来。具体的，这里只涉及一种定时事件，即定期检测非活跃连接，这里将该定时事件与连接资源封装为一个结构体定时器。**定时器容器**，是指使用某种容器类[数据结构](https://so.csdn.net/so/search?q=数据结构&spm=1001.2101.3001.7020)，将上述多个定时器组合起来，便于对定时事件统一管理。具体的，项目中使用升序链表将所有定时器串联组织起来。

**Linux下提供了三种定时的方法**:

- socket选项SO_RECVTIMEO和SO_SNDTIMEO
- SIGALRM信号
- I/O复用系统调用的超时参数

**三种方法没有一劳永逸的应用场景**，也没有绝对的优劣。由于项目中使用的是SIGALRM信号，这里仅对其进行介绍，另外两种方法可以查阅游双的Linux高性能服务器编程 第11章 定时器。
**具体的**，利用alarm函数周期性地触发SIGALRM信号，信号处理函数利用管道通知主循环，主循环接收到该信号后对升序链表上所有定时器进行处理，若该段时间内没有交换数据，则将该连接关闭，释放所占用的资源。
从上面的简要描述中，可以看出定时器处理非活动连接模块，主要分为两部分，其一为定时方法与信号通知流程，其二为定时器及其容器设计与定时任务的处理。

##### 信号通知流程：

Linux下的信号采用的异步处理机制，信号处理函数和当前进程是两条不同的执行路线。具体的，当进程收到信号时，操作系统会中断进程当前的正常流程，转而进入信号处理函数执行操作，完成后再返回中断的地方继续执行。

为避免信号竞态现象发生，信号处理期间系统不会再次触发它。所以，为确保该信号不被屏蔽太久，信号处理函数需要尽可能快地执行完毕。

一般的信号处理函数需要处理该信号对应的逻辑，当该逻辑比较复杂时，信号处理函数执行时间过长，会导致信号屏蔽太久。

这里的解决方案是，信号处理函数仅仅发送信号通知程序主循环，将信号对应的处理逻辑放在程序主循环中，由主循环执行信号对应的逻辑代码。

**统一事件源**

统一事件源，是指将信号事件与其他事件一样被处理。

具体的，信号处理函数使用管道将信号传递给主循环，信号处理函数往管道的写端写入信号值，主循环则从管道的读端读出信号值，使用I/O复用系统调用来监听管道读端的可读事件，这样信号事件与其他文件描述符都可以通过epoll来监测，从而实现统一处理。

##### **信号处理机制**

每个进程之中，都有存着一个表，里面存着每种信号所代表的含义，内核通过设置表项中每一个位来标识对应的信号类型。


![图片](https://mmbiz.qpic.cn/mmbiz_jpg/6OkibcrXVmBF4pFdWIo9AHPnib7HCeX9t4u3DhF2ywtNlamuVEDmd0IGDI3klPTJpPvjvric8U490RvzueCe7icTOg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

- 信号的接收
  - 接收信号的任务是由内核代理的，当内核接收到信号后，会将其放到对应进程的信号队列中，同时向进程发送一个中断，使其陷入内核态。注意，此时信号还只是在队列中，对进程来说暂时是不知道有信号到来的。

- 信号的检测
  - 进程从内核态返回到用户态前进行信号检测
  - 进程在内核态中，从睡眠状态被唤醒的时候进行信号检测
  - 进程陷入内核态后，有两种场景会对信号进行检测：
  - 当发现有新信号时，便会进入下一步，信号的处理。

- 信号的处理
  - ( **内核** )信号处理函数是运行在用户态的，调用处理函数前，内核会将当前内核栈的内容备份拷贝到用户栈上，并且修改指令寄存器（eip）将其指向信号处理函数。
  - ( **用户** )接下来进程返回到用户态中，执行相应的信号处理函数。
  - ( **内核** )信号处理函数执行完成后，还需要返回内核态，检查是否还有其它信号未处理。
  - ( **用户** )如果所有信号都处理完成，就会将内核栈恢复（从用户栈的备份拷贝回来），同时恢复指令寄存器（eip）将其指向中断前的运行位置，最后回到用户态继续执行进程。

至此，一个完整的信号处理流程便结束了，如果同时有多个信号到达，上面的处理流程会在第2步和第3步骤间重复进行。

## 9、LOG日志系统

- 日志
  - 由服务器自动创建，并记录运行状态，错误信息，访问数据的文件

同步日志与异步日志
同步日志：日志写入函数与工作线程串行执行，由于涉及到I/O操作，当单条日志比较大的时候，同步模式会阻塞整个处理流程，服务器所能处理的并发能力将有所下降，尤其是在峰值的时候，写日志可能成为系统的瓶颈

异步日志：将所写的日志内容先存入阻塞队列中，写线程从阻塞队列中取出内容，写入日志

- 生产者-消费者模型
  - 并发编程中的经典模型
  - 以多线程为例，为了实现线程间数据同步，生产者线程与消费者线程共享一个缓冲区，其中生产者线程往缓冲区中push消息，消费者线程从缓冲区中pop消息

- 阻塞队列
  - 将生产者-消费者模型进行封装，使用循环数组实现队列，作为两者共享的缓冲区

- 单例模式
  - 最常用的设计模式之一，保证一个类仅有一个实例，并提供一个访问它的全局访问点，该实例被所有程序模块共享

### 同步日志与异步日志的比较

- 同步日志
  - 优点
    - **代码简单** 同步日志是在主线程中直接输出日志，代码相对简单。不需要处理线程间同步和异步问题
    - **日志输出顺序可控** 同步日志是按照输入的顺序直接输出，因此输出的顺序比较可控，可以保证日志的顺序
    - **传统且易于调试** 同步日志是较传统的方式，易于排错和调试
  - 缺点
    - **性能问题** 由于同步日志是在主线程中直接输出，因此它会阻塞该线程，增加了主线程I/O等待的时间，可能会导致性能问题
    - **安全问题** 如果在写日志时程序崩溃或被强制关闭，会导致日志数据丢失
    - **时间上的依赖** 同步日志的输出时间与输入时间相同，这可能会对程序的性能造成负面影响
  - 适用范围
    - ***同步日志适用于需要简单、稳定且扩展性不是很高的场景，如一些小型程序或者进行调试的场景***

- 异步日志
  - 优点
    - **时间上的独立** 异步日志是把日志数据缓存到内存或磁盘中，由专门的线程来将缓存的数据输出到日志文件或其他存储介质中，这样就可以将日志输入的时间与日志输出时间分开，并且不会被I/O等待时间影响，提高了日志输入的效率
    - **数据安全** 异步日志通过将日志数据缓存到内存或磁盘中来避免了数据丢失。即使程序突然崩溃或被强制关闭，尚未输出的日志数据也已被保存，避免了数据丢失
    - **减少I/O负担** 异步日志通过将日志数据缓存到内存或磁盘中来避免了大量的I/O操作，从而减轻了I/O操作对系统的负担，提高了程序的性能
  - 缺点
    - **多线程同步** 异步日志需要多线程共同完成逻辑，如果线程同步不好处理，就可能出现竞争条件和死锁等问题
    - **日志顺序问题** 由于异步日志是异步输出的，因此无法保证日志输出的顺序与其输入的顺序一致。这可能会在某些情况下引起问题
    - **代码复杂性** 实现异步日志通常需要使用多线程编程、线程同步等技术，从而增加了代码的复杂性和难度
  - 适用范围
    - ***异步日志适用于需要大量日志输出和较高的日志处理速度的场景，如高并发的网络服务器应用程序***

#### 单例模式

- 实现思路
  - 私有化它的构造函数，以防止外界创建单例类的对象
  - 使用类的私有静态指针变量指向类的唯一实例
  - 用一个公有的静态方法获取该实例
- 两种实现方式

##### 日志类流程

![日志功能流程图](https://img-blog.csdnimg.cn/34c2573925304d42a93b0801777b3376.jpeg#pic_center)

- 日志文件
  - 局部变量的懒汉模式获取实例
  - 生成日志文件，并判断同步和异步写入方式
- 同步写入
  - 判断是否分文件
  - 直接格式化输出内容，将信息写入日志文件
- 异步写入
  - 判断是否分文件
  - 格式化输出内容，将内容写入阻塞队列，创建一个写线程，从阻塞队列取出内容写入日志文件

## 12、注册登录

### 流程图：

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/6OkibcrXVmBF79BLANEZ6cQoucgxyIz8B0Mz7VGZVTv4MpQC7pLL2bZiaic7sAVz2lhyk8ibL95apWmSE8AfGxAx6A/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)